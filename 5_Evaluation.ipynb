{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4d4b11",
   "metadata": {},
   "source": [
    "# Evaluation <a id='top'></a>\n",
    "\n",
    "In this last notebook, we start evaluating our newly trained recommendation systems for new users. \n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "\n",
    "[0. Import Libraries](#libraries) <br>\n",
    "[1. Create Necessary Functions](#functions) <br>\n",
    "&emsp; [1.1. Evaluation Function](#evaluate) <br>\n",
    "&emsp; [1.2. Plot Evaluation Function](#plot_evaluate) <br>\n",
    "&emsp; [1.3. Evaluate and Visualize Function](#evaluate_visualize) <br>\n",
    "[2. Evaluate Recommendation Systems ](#apply_functions) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aefbf2",
   "metadata": {},
   "source": [
    "# 0. Import libraries <a id='libraries'></a>\n",
    "[to the top](#top)\n",
    "\n",
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f38356c-9382-46ee-8fcf-b03c911c4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, precision_score, recall_score, f1_score\n",
    "from model import UserBasedCF, ItemBasedCF, MatrixFactorizationCF\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from helper_functions import load_config, load_data, format_timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587549c",
   "metadata": {},
   "source": [
    "# 1. Create Necessary Functions <a id='functions'></a>\n",
    "[to the top](#top)\n",
    "\n",
    "In this section of the notebook, we start by defining the functions we are going to use to evaluate the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724ad7b",
   "metadata": {},
   "source": [
    "## 1.1. Evaluation Function <a id='evaluate'></a>\n",
    "[to the top](#top)\n",
    "\n",
    "This function evaluates the performance of a recommendation model by comparing its predictions against the actual ratings in the test dataset. It calculates several metrics including Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Precision, Recall, and F1-score. Precision, Recall, and F1-score are computed using a binary classification approach, assuming a threshold of 3 for relevant ratings. These metrics provide insights into the accuracy and effectiveness of the recommendation model in predicting user preferences and can help guide further model refinement and optimization efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c478c8-5452-4aac-bb63-edecbd031c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    # Initialize NumPy arrays for actual and predicted ratings\n",
    "    y_true = np.zeros(len(test_data))\n",
    "    y_pred = np.zeros(len(test_data))\n",
    "\n",
    "    # Fill the arrays with actual and predicted ratings\n",
    "    for i, row in enumerate(test_data.itertuples()):\n",
    "        user_id = row.user_id\n",
    "        game_id = row.game_id\n",
    "        actual_rating = row.rating\n",
    "\n",
    "        prediction = model.predict(user_id, game_id)\n",
    "        y_true[i] = actual_rating\n",
    "        y_pred[i] = prediction\n",
    "\n",
    "    # Check for NaN values and remove them\n",
    "    valid_indices = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    y_true = y_true[valid_indices]\n",
    "    y_pred = y_pred[valid_indices]\n",
    "\n",
    "    # Mean Absolute Error\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Root Mean Squared Error\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Precision, Recall, F1-score (assuming threshold for relevant rating is > 3)\n",
    "    y_true_binary = (y_true > 3).astype(int)\n",
    "    y_pred_binary = (y_pred > 3).astype(int)\n",
    "\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'Precision': precision, 'Recall': recall, 'F1-score': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acfacd0",
   "metadata": {},
   "source": [
    "## 1.2. Plot Evaluation Function <a id='plot_evaluate'></a>\n",
    "[to the top](#top)\n",
    "\n",
    "This function plots the evaluation results of a recommendation model, visualizing various performance metrics. It takes a dictionary of results containing metric names as keys and corresponding scores as values, along with the name of the model being evaluated. The function extracts metric labels and scores from the dictionary, plots them as a bar chart, and labels the axes appropriately. The resulting plot provides a concise overview of the model's performance across different evaluation metrics, aiding in the comparison and interpretation of its effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66670161-2a6a-430a-9e12-7d9874f9a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_results(results, model_name):\n",
    "    labels, values = zip(*results.items())\n",
    "    x = np.arange(len(labels))\n",
    "    plt.bar(x, values, color='b')\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'{model_name} Evaluation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2f211",
   "metadata": {},
   "source": [
    "## 1.3. Evaluate and Visualize Function <a id='evaluate_visualize'></a>\n",
    "[to the top](#top)\n",
    "\n",
    "This function simplifies the evaluation and visualization process for the recommendation sytems. It loads test data, pre-trained models, and evaluates each model's performance using the evaluate_model function. The evaluation results are then printed, providing insights into the models' performance. Additionally, the function plots the evaluation results for each model, presenting a visual comparison of their performance across various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e774bea1-3289-48d9-b591-42f78fb6d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_and_show_results(reviews_dir, game_details_path, selection_file, selection_name=\"\"):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Starting evaluation for selection: {selection_name}\")\n",
    "    _, test_data = load_data(reviews_dir, game_details_path, selection_file)\n",
    "    data_loading_time = time.time()\n",
    "    print(f\"Data loaded in {format_timedelta(timedelta(seconds=data_loading_time - start_time))}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Evaluate User-Based CF model\n",
    "    print(f\"Loading User-Based CF model for selection: {selection_name}\")\n",
    "    user_based_model = UserBasedCF.load(f'data/model/{selection_name}_user_based_cf_model.pkl')\n",
    "    user_based_loading_time = time.time()\n",
    "    print(f\"User-Based CF model loaded in {format_timedelta(timedelta(seconds=user_based_loading_time - data_loading_time))}\")\n",
    "    \n",
    "    print(f\"Evaluating User-Based CF model for selection: {selection_name}\")\n",
    "    user_based_results = evaluate_model(user_based_model, test_data)\n",
    "    user_based_evaluation_time = time.time()\n",
    "    print(f\"User-Based CF model evaluated in {format_timedelta(timedelta(seconds=user_based_evaluation_time - user_based_loading_time))}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Free memory\n",
    "    del user_based_model\n",
    "    \n",
    "    # Evaluate Item-Based CF model\n",
    "    print(f\"Loading Item-Based CF model for selection: {selection_name}\")\n",
    "    item_based_model = ItemBasedCF.load(f'data/model/{selection_name}_item_based_cf_model.pkl')\n",
    "    item_based_loading_time = time.time()\n",
    "    print(f\"Item-Based CF model loaded in {format_timedelta(timedelta(seconds=item_based_loading_time - user_based_evaluation_time))}\")\n",
    "    \n",
    "    print(f\"Evaluating Item-Based CF model for selection: {selection_name}\")\n",
    "    item_based_results = evaluate_model(item_based_model, test_data)\n",
    "    item_based_evaluation_time = time.time()\n",
    "    print(f\"Item-Based CF model evaluated in {format_timedelta(timedelta(seconds=item_based_evaluation_time - item_based_loading_time))}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Free memory\n",
    "    del item_based_model\n",
    "    \n",
    "    # Evaluate Matrix Factorization CF model\n",
    "    print(f\"Loading Matrix Factorization CF model for selection: {selection_name}\")\n",
    "    matrix_factorization_model = MatrixFactorizationCF.load(f'data/model/{selection_name}_matrix_factorization_cf_model.pkl')\n",
    "    matrix_factorization_loading_time = time.time()\n",
    "    print(f\"Matrix Factorization CF model loaded in {format_timedelta(timedelta(seconds=matrix_factorization_loading_time - item_based_evaluation_time))}\")\n",
    "    \n",
    "    print(f\"Evaluating Matrix Factorization CF model for selection: {selection_name}\")\n",
    "    matrix_factorization_results = evaluate_model(matrix_factorization_model, test_data)\n",
    "    matrix_factorization_evaluation_time = time.time()\n",
    "    print(f\"Matrix Factorization CF model evaluated in {format_timedelta(timedelta(seconds=matrix_factorization_evaluation_time - matrix_factorization_loading_time))}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Free memory\n",
    "    del matrix_factorization_model\n",
    "    \n",
    "    print(f\"Results for selection: {selection_name}\")\n",
    "    print(\"User-Based CF Evaluation Results:\", user_based_results)\n",
    "    print(\"Item-Based CF Evaluation Results:\", item_based_results)\n",
    "    print(\"Matrix Factorization CF Evaluation Results:\", matrix_factorization_results)\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_evaluation_results(user_based_results, f'User-Based CF {selection_name}')\n",
    "    plot_evaluation_results(item_based_results, f'Item-Based CF {selection_name}')\n",
    "    plot_evaluation_results(matrix_factorization_results, f'Matrix Factorization CF {selection_name}')\n",
    "    \n",
    "    plotting_time = time.time()\n",
    "    print(f\"Results plotted in {format_timedelta(timedelta(seconds=plotting_time - matrix_factorization_evaluation_time))}\")\n",
    "    \n",
    "    total_time = plotting_time - start_time\n",
    "    print(f\"Total evaluation time for selection {selection_name}: {format_timedelta(timedelta(seconds=total_time))}\")\n",
    "    print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3f220",
   "metadata": {},
   "source": [
    "# 2. Evaluate Recommendation Systems <a id='apply_functions'></a>\n",
    "[to the top](#top)\n",
    "\n",
    "Finally, we apply our new functions to evaluate our recommendation systems with different metrics and plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f408a2-1155-4fc2-8ffb-8b2cbc13680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for selection: most_played_preprocessed_low_review_count\n",
      "Data loaded in 0h 0m 0s\n",
      "----------------------------------------\n",
      "Loading User-Based CF model for selection: most_played_preprocessed_low_review_count\n",
      "User-Based CF model loaded in 0h 0m 0s\n",
      "Evaluating User-Based CF model for selection: most_played_preprocessed_low_review_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variation, params \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mget_evaluate_and_show_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviews_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgame_details_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselection_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselection_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mget_evaluate_and_show_results\u001b[1;34m(reviews_dir, game_details_path, selection_file, selection_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Based CF model loaded in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_timedelta(timedelta(seconds\u001b[38;5;241m=\u001b[39muser_based_loading_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mdata_loading_time))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating User-Based CF model for selection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m user_based_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_based_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m user_based_evaluation_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Based CF model evaluated in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_timedelta(timedelta(seconds\u001b[38;5;241m=\u001b[39muser_based_evaluation_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39muser_based_loading_time))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_data)\u001b[0m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Mean Absolute Error\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Root Mean Squared Error\u001b[39;00m\n\u001b[0;32m     22\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_true, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:204\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    141\u001b[0m     {\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m ):\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    208\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    100\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    104\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "for variation, params in config.items():\n",
    "    get_evaluate_and_show_results(\n",
    "        params['reviews_dir'],\n",
    "        params['game_details_path'],\n",
    "        params['selection_file'],\n",
    "        params['selection_name']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
