{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d9d0ca",
   "metadata": {},
   "source": [
    "# Data Selection <a id='top'></a>\n",
    "\n",
    "After acquiring and exploring our data, it is time to start slecting what is going to be used in our model. In this notebook, we partition the games into two categories based on a predefined threshold of 50,000 reviews: those with high review counts and those with low review counts. By saving the lists of corresponding app IDs to text files, we are now ready to start training our model.\n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "\n",
    "[0. Import Libraries](#libraries) <br>\n",
    "[1. Data Selection](#select) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e677d0c",
   "metadata": {},
   "source": [
    "# 0. Import Libraries<a id='libraries'></a>\n",
    "[to the top](#top)  \n",
    "\n",
    "The first step is to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f64e11a-fb18-4981-ae82-f2f5940de041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from helper_functions import get_parquets_data_info, save_appids_to_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653d682",
   "metadata": {},
   "source": [
    "# 1. Data Selection<a id='select'></a>\n",
    "[to the top](#top)  \n",
    "\n",
    "In this section of the notebook, we start by getting the reviews and then separate it into two groups: one that has games with a high amount of reviews and another one that contains the remaining games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8febe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_folder_path = 'data/parquets'\n",
    "parquet_preprocessed_folder_path = 'data/parquets_preprocessed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec27fe",
   "metadata": {},
   "source": [
    "The get_parquets_data_info function processes all Parquet files within a specified folder, extracting relevant information from their filenames and combining it with data from a JSON file (SteamGames.json). It begins by defining a function to extract app ID and review count from each Parquet file's filename using a regular expression. Then, it searches for all Parquet files in the folder, extracts and stores the relevant information. Next, it loads the SteamGames.json file to obtain the mapping between app IDs and game names. It creates a lookup dictionary for fast app ID to name conversion. Finally, it adds the game name to the collected data and constructs a Polars DataFrame containing file names, app IDs, game names, and review counts, which is returned for further analysis or processing. This function facilitates data exploration and understanding by providing an organized summary of Parquet file contents alongside corresponding game names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d5d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquets = get_parquets_data_info(parquet_folder_path)\n",
    "df_parquets_preprocessed = get_parquets_data_info(parquet_preprocessed_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496b262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 0)</small><table border=\"1\" class=\"dataframe\"><thead><tr></tr><tr></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 0)\n",
       "┌┐\n",
       "╞╡\n",
       "└┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parquets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad7c4c0-0277-4681-95b6-1d2cc1a0ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 0)</small><table border=\"1\" class=\"dataframe\"><thead><tr></tr><tr></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 0)\n",
       "┌┐\n",
       "╞╡\n",
       "└┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parquets_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e76e9e-645a-4fc2-9164-e371b9f9db27",
   "metadata": {},
   "source": [
    "The provided code segment sets a threshold of 50,000 reviews and divides a DataFrame df_parquets into two subsets: one containing app IDs with review counts exceeding the threshold (high_review_df) and the other containing app IDs with review counts below the threshold (low_review_df). It then extracts app IDs from each subset, converts them to lists, and prints the number of app IDs in each subset. Additionally, it saves the lists of app IDs to text files named \"high_review_games.txt\" and \"low_review_games.txt\" using a function save_appids_to_txt. This approach allows for the segmentation of games based on review counts, facilitating further analysis or targeted actions based on review volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ae6015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high:23\n",
      "low:487\n"
     ]
    }
   ],
   "source": [
    "threshold = 50000\n",
    "\n",
    "high_review_df = df_parquets.filter(pl.col(\"review_count\") > threshold)\n",
    "high_review_appid_list = high_review_df.select(\"appid\").to_series().to_list()\n",
    "print(f\"high:{len(high_review_appid_list)}\")\n",
    "\n",
    "# Save the list of appids to a text file\n",
    "save_appids_to_txt(high_review_appid_list, 'data/high_review_games.txt')\n",
    "\n",
    "low_review_df = df_parquets.filter(pl.col(\"review_count\") < threshold)\n",
    "low_review_appid_list = low_review_df.select(\"appid\").to_series().to_list()\n",
    "print(f\"low:{len(low_review_appid_list)}\")\n",
    "\n",
    "# Save the list of appids to a text file\n",
    "save_appids_to_txt(low_review_appid_list, 'data/low_review_games.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
